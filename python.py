# python.py

import streamlit as st
import pandas as pd
from google import genai
@@ -11,7 +9,7 @@
layout="wide"
)

st.title("·ª®ng d·ª•ng Ph√¢n T√≠ch B√°o C√°o T√†i Ch√≠nh üìä")
st.title("·ª®ng d·ª•ng Ph√¢n T√≠ch B√°o C√°o T√†i ch√≠nh üìä")

# --- H√†m t√≠nh to√°n ch√≠nh (S·ª≠ d·ª•ng Caching ƒë·ªÉ T·ªëi ∆∞u hi·ªáu su·∫•t) ---
@st.cache_data
@@ -53,7 +51,7 @@ def process_financial_data(df):

return df

# --- H√†m g·ªçi API Gemini ---
# --- H√†m g·ªçi API Gemini cho Ph√¢n t√≠ch T√†i ch√≠nh (Ch·ª©c nƒÉng 5) ---
def get_ai_analysis(data_for_ai, api_key):
"""G·ª≠i d·ªØ li·ªáu ph√¢n t√≠ch ƒë·∫øn Gemini API v√† nh·∫≠n nh·∫≠n x√©t."""
try:
@@ -80,13 +78,21 @@ def get_ai_analysis(data_for_ai, api_key):
except Exception as e:
return f"ƒê√£ x·∫£y ra l·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"

# --------------------------------------------------------------------------------------
# --- LOGIC CHUNG C·ª¶A ·ª®NG D·ª§NG ---
# --------------------------------------------------------------------------------------

# --- Ch·ª©c nƒÉng 1: T·∫£i File ---
uploaded_file = st.file_uploader(
"1. T·∫£i file Excel B√°o c√°o T√†i ch√≠nh (Ch·ªâ ti√™u | NƒÉm tr∆∞·ªõc | NƒÉm sau)",
type=['xlsx', 'xls']
)

# Kh·ªüi t·∫°o gi√° tr·ªã m·∫∑c ƒë·ªãnh cho ch·ªâ s·ªë thanh to√°n
thanh_toan_hien_hanh_N = "N/A"
thanh_toan_hien_hanh_N_1 = "N/A"
df_processed = None

if uploaded_file is not None:
try:
df_raw = pd.read_excel(uploaded_file)
@@ -113,20 +119,17 @@ def get_ai_analysis(data_for_ai, api_key):
st.subheader("4. C√°c Ch·ªâ s·ªë T√†i ch√≠nh C∆° b·∫£n")

try:
                # L·ªçc gi√° tr·ªã cho Ch·ªâ s·ªë Thanh to√°n Hi·ªán h√†nh (V√≠ d·ª•)
                
# L·∫•y T√†i s·∫£n ng·∫Øn h·∫°n
tsnh_n = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm sau'].iloc[0]
tsnh_n_1 = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm tr∆∞·ªõc'].iloc[0]

                # L·∫•y N·ª£ ng·∫Øn h·∫°n (D√πng gi√° tr·ªã gi·∫£ ƒë·ªãnh ho·∫∑c l·ªçc t·ª´ file n·∫øu c√≥)
                # **L∆ØU √ù: Thay th·∫ø logic sau n·∫øu b·∫°n c√≥ N·ª£ Ng·∫Øn H·∫°n trong file**
                # L·∫•y N·ª£ ng·∫Øn h·∫°n
no_ngan_han_N = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('N·ª¢ NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm sau'].iloc[0]  
no_ngan_han_N_1 = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('N·ª¢ NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm tr∆∞·ªõc'].iloc[0]

                # T√≠nh to√°n
                thanh_toan_hien_hanh_N = tsnh_n / no_ngan_han_N
                thanh_toan_hien_hanh_N_1 = tsnh_n_1 / no_ngan_han_N_1
                # T√≠nh to√°n, tr√°nh chia cho 0
                thanh_toan_hien_hanh_N = tsnh_n / no_ngan_han_N if no_ngan_han_N != 0 else 0
                thanh_toan_hien_hanh_N_1 = tsnh_n_1 / no_ngan_han_N_1 if no_ngan_han_N_1 != 0 else 0

col1, col2 = st.columns(2)
with col1:
@@ -142,14 +145,18 @@ def get_ai_analysis(data_for_ai, api_key):
)

except IndexError:
                 st.warning("Thi·∫øu ch·ªâ ti√™u 'T√ÄI S·∫¢N NG·∫ÆN H·∫†N' ho·∫∑c 'N·ª¢ NG·∫ÆN H·∫†N' ƒë·ªÉ t√≠nh ch·ªâ s·ªë.")
                 thanh_toan_hien_hanh_N = "N/A" # D√πng ƒë·ªÉ tr√°nh l·ªói ·ªü Ch·ª©c nƒÉng 5
                 thanh_toan_hien_hanh_N_1 = "N/A"
                st.warning("Thi·∫øu ch·ªâ ti√™u 'T√ÄI S·∫¢N NG·∫ÆN H·∫†N' ho·∫∑c 'N·ª¢ NG·∫ÆN H·∫†N' ƒë·ªÉ t√≠nh ch·ªâ s·ªë.")
                thanh_toan_hien_hanh_N = "N/A" 
                thanh_toan_hien_hanh_N_1 = "N/A"

# --- Ch·ª©c nƒÉng 5: Nh·∫≠n x√©t AI ---
st.subheader("5. Nh·∫≠n x√©t T√¨nh h√¨nh T√†i ch√≠nh (AI)")

# Chu·∫©n b·ªã d·ªØ li·ªáu ƒë·ªÉ g·ª≠i cho AI
            # C·∫ßn ƒë·∫£m b·∫£o thanh_toan_hien_hanh_N kh√¥ng ph·∫£i "N/A" khi g·ª≠i
            tt_N = f"{thanh_toan_hien_hanh_N:.2f}" if isinstance(thanh_toan_hien_hanh_N, float) else thanh_toan_hien_hanh_N
            tt_N_1 = f"{thanh_toan_hien_hanh_N_1:.2f}" if isinstance(thanh_toan_hien_hanh_N_1, float) else thanh_toan_hien_hanh_N_1
            
data_for_ai = pd.DataFrame({
'Ch·ªâ ti√™u': [
'To√†n b·ªô B·∫£ng ph√¢n t√≠ch (d·ªØ li·ªáu th√¥)', 
@@ -160,8 +167,8 @@ def get_ai_analysis(data_for_ai, api_key):
'Gi√° tr·ªã': [
df_processed.to_markdown(index=False),
f"{df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)]['T·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng (%)'].iloc[0]:.2f}%", 
                    f"{thanh_toan_hien_hanh_N_1}", 
                    f"{thanh_toan_hien_hanh_N}"
                    tt_N_1, 
                    tt_N
]
}).to_markdown(index=False) 

@@ -174,7 +181,7 @@ def get_ai_analysis(data_for_ai, api_key):
st.markdown("**K·∫øt qu·∫£ Ph√¢n t√≠ch t·ª´ Gemini AI:**")
st.info(ai_result)
else:
                     st.error("L·ªói: Kh√¥ng t√¨m th·∫•y Kh√≥a API. Vui l√≤ng c·∫•u h√¨nh Kh√≥a 'GEMINI_API_KEY' trong Streamlit Secrets.")
                    st.error("L·ªói: Kh√¥ng t√¨m th·∫•y Kh√≥a API. Vui l√≤ng c·∫•u h√¨nh Kh√≥a 'GEMINI_API_KEY' trong Streamlit Secrets.")

except ValueError as ve:
st.error(f"L·ªói c·∫•u tr√∫c d·ªØ li·ªáu: {ve}")
@@ -183,3 +190,92 @@ def get_ai_analysis(data_for_ai, api_key):

else:
st.info("Vui l√≤ng t·∫£i l√™n file Excel ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch.")

# --------------------------------------------------------------------------------------
# --- CH·ª®C NƒÇNG B·ªî SUNG: KHUNG CHAT GEMINI ---
# --------------------------------------------------------------------------------------

st.divider()
st.header("üí¨ Tr√≤ chuy·ªán v·ªõi Gemini (H·ªèi ƒê√°p Chung)")

# L·∫•y API Key t·ª´ Streamlit Secrets
api_key = st.secrets.get("GEMINI_API_KEY")
MODEL_NAME_CHAT = 'gemini-2.5-flash'

# 1. Kh·ªüi t·∫°o Client v√† Session
try:
    if not api_key:
        st.warning("‚ö†Ô∏è Vui l√≤ng c·∫•u h√¨nh Kh√≥a 'GEMINI_API_KEY' trong Streamlit Secrets ƒë·ªÉ s·ª≠ d·ª•ng t√≠nh nƒÉng chat.")
        client = None
    else:
        client = genai.Client(api_key=api_key)

except Exception as e:
    st.error(f"L·ªói khi kh·ªüi t·∫°o Gemini Client cho Chat: {e}")
    client = None

# H√†m kh·ªüi t·∫°o ho·∫∑c l·∫•y ƒë·ªëi t∆∞·ª£ng chat
def get_chat_session(client):
    """Kh·ªüi t·∫°o ho·∫∑c tr·∫£ v·ªÅ ƒë·ªëi t∆∞·ª£ng Chat Session t·ª´ Gemini."""
    if client and "chat_session" not in st.session_state:
        # Kh·ªüi t·∫°o m·ªôt ƒë·ªëi t∆∞·ª£ng chat m·ªõi
        st.session_state.chat_session = client.chats.create(
            model=MODEL_NAME_CHAT,
            system_instruction="B·∫°n l√† m·ªôt tr·ª£ l√Ω ·∫£o th√¢n thi·ªán v√† h·ªØu √≠ch, chuy√™n gi·∫£i ƒë√°p m·ªçi th·∫Øc m·∫Øc c·ªßa ng∆∞·ªùi d√πng. H√£y tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát."
        )
        st.session_state.messages = [] # L∆∞u tr·ªØ l·ªãch s·ª≠ tin nh·∫Øn
    
    # Tr·∫£ v·ªÅ session n·∫øu client h·ª£p l·ªá, n·∫øu kh√¥ng tr·∫£ v·ªÅ None
    return st.session_state.chat_session if client else None

chat = get_chat_session(client)

if chat:
    # 2. Hi·ªÉn th·ªã l·ªãch s·ª≠ tin nh·∫Øn
    for message in st.session_state.messages:
        role = "user" if message["role"] == "user" else "assistant"
        with st.chat_message(role):
            st.markdown(message["content"])

    # 3. √î NH·∫¨P LI·ªÜU (Chat Input)
    if prompt := st.chat_input("B·∫°n mu·ªën h·ªèi Gemini ƒëi·ªÅu g√¨?"):
        # Hi·ªÉn th·ªã tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # L∆∞u tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠
        st.session_state.messages.append({"role": "user", "content": prompt})

        # G·ª≠i tin nh·∫Øn ƒë·∫øn Gemini v√† hi·ªÉn th·ªã ph·∫£n h·ªìi
        with st.chat_message("assistant"):
            # S·ª≠ d·ª•ng st.spinner ƒë·ªÉ hi·ªÉn th·ªã tr·∫°ng th√°i t·∫£i
            with st.spinner("ƒêang g·ª≠i ƒë·∫øn Gemini..."):
                try:
                    # G·ª≠i tin nh·∫Øn (prompt) t·ªõi phi√™n chat v·ªõi streaming
                    response = chat.send_message(prompt, stream=True)
                    
                    # T·∫°o m·ªôt placeholder ƒë·ªÉ vi·∫øt c√¢u tr·∫£ l·ªùi t·ª´ng ph·∫ßn
                    full_response = ""
                    message_placeholder = st.empty()
                    
                    for chunk in response:
                        # N·ªëi c√°c ph·∫ßn n·ªôi dung nh·∫≠n ƒë∆∞·ª£c
                        full_response += chunk.text
                        # C·∫≠p nh·∫≠t placeholder v·ªõi n·ªôi dung ƒë√£ n·ªëi
                        message_placeholder.markdown(full_response + "‚ñå") # Th√™m con tr·ªè nh·∫•p nh√°y

                    # C·∫≠p nh·∫≠t l·∫°i v·ªõi n·ªôi dung ho√†n ch·ªânh
                    message_placeholder.markdown(full_response)
                    
                    # 4. L∆∞u ph·∫£n h·ªìi v√†o l·ªãch s·ª≠
                    st.session_state.messages.append({"role": "assistant", "content": full_response})

                except Exception as e:
                    error_message = f"ƒê√£ x·∫£y ra l·ªói khi giao ti·∫øp v·ªõi Gemini: {e}"
                    st.error(error_message)
                    # X√≥a tin nh·∫Øn cu·ªëi c√πng c·ªßa ng∆∞·ªùi d√πng n·∫øu c√≥ l·ªói
                    if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
                        st.session_state.messages.pop()
else:
    # Ch·ªâ hi·ªán th·ªã th√¥ng b√°o n·∫øu client kh√¥ng ƒë∆∞·ª£c kh·ªüi t·∫°o
    pass
